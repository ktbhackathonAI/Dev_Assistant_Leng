import os
import logging

from langchain_community.vectorstores import FAISS
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader


class SentenceTransformerWrapper:
    """FAISSì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ `SentenceTransformer`ì„ ë˜í•‘í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str):
        self.model = SentenceTransformer(model_name, trust_remote_code=True)

    def embed_documents(self, texts: list) -> list:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        return self.model.encode(texts, normalize_embeddings=True).tolist()

    def embed_query(self, text: str) -> list:
        """ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        return self.model.encode([text], normalize_embeddings=True).tolist()[0]
    

class RAGRetriever:
    """ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬í•œ ê°œë°œ ìš©ì–´ë¥¼ ê²€ìƒ‰í•˜ëŠ” RAG ê¸°ëŠ¥"""
    
    vector_store_path = "./vector_store/faiss"
    pdf_path = "./vector_store/vector_store_pdf.pdf"
    embedding_model = SentenceTransformerWrapper("intfloat/multilingual-e5-large")
    vector_store = None  # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
    index = None  # ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥

    @classmethod
    def search_similar_terms(cls, query: str, top_k: int = 3):
        """ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ê°œë°œ ìš©ì–´ ê²€ìƒ‰"""
        if cls.vector_store is None:
            logging.info("ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰ì¤‘..")
        cls._load_vector_store()
        results = cls.vector_store.similarity_search(query, k=top_k)
        return [res.page_content for res in results]
    
    @classmethod
    def _load_vector_store(cls):
        """ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        if os.path.exists(cls.vector_store_path):
            cls.vector_store = FAISS.load_local(cls.vector_store_path, cls.embedding_model.embed_query, allow_dangerous_deserialization=True)
            cls.index = cls.vector_store.index
            logging.info("âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
        elif os.path.exists(cls.pdf_path):
            logging.error("âš  ì‚¬ì „ êµ¬ì¶•ëœ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹ ê·œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.")
            docs = cls._build_docs()

            texts = [doc.page_content for doc in docs]
            embeddings = cls.embedding_model.embed_documents(texts)

            text_embedding_pairs = list(zip(texts, embeddings))

            cls.vector_store = FAISS.from_embeddings(
                text_embeddings=text_embedding_pairs,
                embedding=cls.embedding_model.embed_query
            )

            cls.vector_store.save_local(cls.vector_store_path)
        else:
            logging.error("âŒ PDFë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë°œ ìš©ì–´ PDFê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            raise FileNotFoundError("Vector store not found. Ensure it is pre-built.")


    @classmethod
    def _build_docs(cls):
        loader = PyPDFLoader(cls.pdf_path)
        pages = loader.load_and_split()

        full_text = "".join([page.page_content for page in pages])

        # ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ splití•˜ëŠ” Text Splitter ìƒì„±
        text_splitter = CharacterTextSplitter(
            separator="\n \n",  # ì¤„ ë‹¨ìœ„ë¡œ ë¶„í• 
            chunk_size=500,    # í•œ ì¤„ì”© ê°œë…ì„ ë‚˜ëˆ„ë„ë¡ ì„¤ì •
            chunk_overlap=0
        )

        # ë¬¸ì„œ ë°ì´í„° ë¶„í• 
        docs = text_splitter.create_documents([full_text])

        for doc in docs:
            doc.page_content = doc.page_content.replace("\n", "")

        return docs


# # ì˜ˆì œ ì‹¤í–‰
if __name__ == "__main__":
    print("âœ… ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì‘")

    logging.basicConfig(level=logging.INFO)  # ë¡œê·¸ ì„¤ì • (í„°ë¯¸ë„ ì¶œë ¥)
    
    retriever = RAGRetriever()  # RAG ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    example_query = "ê²Œì‹œíŒ CRUD í”„ë¡œê·¸ë¨ ë§Œë“¤ì–´ì¤˜"  # ê²€ìƒ‰í•  ë¬¸ì¥
    similar_terms = retriever.search_similar_terms(example_query)  # ê²€ìƒ‰ ì‹¤í–‰
    
    print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼:\n{similar_terms}\n")  # ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
